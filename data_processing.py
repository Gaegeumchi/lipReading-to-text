import cv2
import mediapipe as mp
import json
import numpy as np
import os
from tqdm import tqdm

# ğŸ”¹ Mediapipe ì´ˆê¸°í™”
mp_face_mesh = mp.solutions.face_mesh
face_mesh = mp_face_mesh.FaceMesh(min_detection_confidence=0.5, min_tracking_confidence=0.5)

# ğŸ”¹ ë°ì´í„° í´ë” ê²½ë¡œ
DATASET_FOLDER = "dataset/"  # ì—¬ê¸°ì— MP4 + JSON íŒŒì¼ì´ ìˆìŒ

# ğŸ”¹ ì…ìˆ  ì¢Œí‘œ ë° ë¼ë²¨ì„ ì €ì¥í•  ë¦¬ìŠ¤íŠ¸
lip_data = []
labels = []

# ğŸ”¹ ëª¨ë“  JSON íŒŒì¼ íƒìƒ‰
json_files = [f for f in os.listdir(DATASET_FOLDER) if f.endswith(".json")]

for json_file in tqdm(json_files, desc="ğŸ“‚ Processing JSON Files"):
    json_path = os.path.join(DATASET_FOLDER, json_file)

    # ğŸ”¹ JSON íŒŒì¼ ë¡œë“œ
    with open(json_path, "r", encoding="utf-8") as f:
        dataset = json.load(f)

    # ğŸ”¹ MP4 ì˜ìƒ íŒŒì¼ëª… ê°€ì ¸ì˜¤ê¸°
    video_name = dataset[0]["Video_info"]["video_Name"]
    video_path = os.path.join(DATASET_FOLDER, video_name)

    # ğŸ”¹ MP4 íŒŒì¼ ì¡´ì¬ í™•ì¸
    if not os.path.exists(video_path):
        print(f"âŒ íŒŒì¼ ì—†ìŒ: {video_path}")
        continue

    # ğŸ”¹ ë™ì˜ìƒ ì²˜ë¦¬ ì‹œì‘
    cap = cv2.VideoCapture(video_path)
    fps = int(cap.get(cv2.CAP_PROP_FPS))  # FPS ê°€ì ¸ì˜¤ê¸°
    sentences = dataset[0]["Sentence_info"]

    print(f"ğŸ¥ Processing Video: {video_name} (FPS: {fps})")

    # ğŸ”¹ í”„ë ˆì„ë³„ ì…ìˆ  ì¢Œí‘œ ì¶”ì¶œ
    while cap.isOpened():
        ret, frame = cap.read()
        if not ret:
            break

        frame_time = cap.get(cv2.CAP_PROP_POS_MSEC) / 1000  # ì´ˆ ë‹¨ìœ„ ë³€í™˜
        rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
        results = face_mesh.process(rgb_frame)

        if results.multi_face_landmarks:
            for landmarks in results.multi_face_landmarks:
                # ì…ìˆ  ì¢Œí‘œë§Œ ì¶”ì¶œ (468ê°œ ì¤‘ ì…ìˆ  ê´€ë ¨ ëœë“œë§ˆí¬ ì¸ë±ìŠ¤)
                lip_indices = [
                    61, 146, 91, 181, 84, 17, 314, 405, 321, 375, 
                    78, 191, 80, 81, 82, 13, 312, 311, 310, 415, 308
                ]
                lip_points = np.array([(landmarks.landmark[i].x, landmarks.landmark[i].y) for i in lip_indices])

                # ğŸ”¹ í˜„ì¬ í”„ë ˆì„ì´ í•´ë‹¹ ë¬¸ì¥ ë²”ìœ„ ë‚´ì— ìˆëŠ”ì§€ í™•ì¸
                label = None
                for sentence in sentences:
                    if sentence["start_time"] <= frame_time <= sentence["end_time"]:
                        label = sentence["sentence_text"]
                        break

                if label:
                    lip_data.append(lip_points.flatten())  # ë²¡í„°í™”
                    labels.append(label)

    cap.release()

# ğŸ”¹ NumPyë¡œ ë³€í™˜ ë° ì €ì¥
lip_data = np.array(lip_data)
np.save("lip_features.npy", lip_data)
with open("labels.txt", "w", encoding="utf-8") as f:
    for label in labels:
        f.write(label + "\n")

print("âœ… ëª¨ë“  ë°ì´í„° ì €ì¥ ì™„ë£Œ: lip_features.npy, labels.txt")